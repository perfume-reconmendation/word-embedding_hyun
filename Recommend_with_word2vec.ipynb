{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Recommend_with_word2vec.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MLqzJm_Svmt2"},"source":["## 문서 벡터를 이용한 추천 시스템(Recommendation System using Document Embedding)"]},{"cell_type":"markdown","metadata":{"id":"cNKwcG3C2cDR"},"source":["## Library Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7ZHm5QFvAsC","executionInfo":{"status":"ok","timestamp":1626614545655,"user_tz":-540,"elapsed":18776,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"379e8743-ac2a-48b6-cb3c-5dbe15d51bd4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=False)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nhJ7dKUqgNb9","executionInfo":{"status":"ok","timestamp":1626619715664,"user_tz":-540,"elapsed":348,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics.pairwise import cosine_similarity\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import re\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","import copy\n","import pickle\n","from collections import OrderedDict\n","import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS"],"execution_count":120,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HmG_T9lX1xfP"},"source":["전체 리뷰 데이터의 string형태를 토큰화된 corpus로 전처리 하는 과정\n","\n","(1회만 수행 후 결과를 pickle로 저장하고 그 후에는 해당 경로를 인자로 입력하여 호출)"]},{"cell_type":"code","metadata":{"id":"ofz4bJyxEhG5","executionInfo":{"status":"ok","timestamp":1626615661418,"user_tz":-540,"elapsed":321,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["# df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/data/dataset_210626_215600.csv')\n","# df.drop('Unnamed: 0', axis=1, inplace=True)\n","# sent_text = df['lemmatizated']\n","# # 원본 데이터의 str부분을 전처리\n","# nltk.download('punkt')\n","# normalized_text = []\n","# for string in sent_text:\n","#     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","#     tokens = ' '.join([w for w in tokens.split() if len(w)>=3])\n","#     normalized_text.append(tokens)\n","# result = []\n","# result = [word_tokenize(sentence) for sentence in normalized_text]\n","\n","# corpus_dir = '/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/data/tokenized_doc.pickle'\n","\n","# # save\n","# with open(corpus_dir, 'wb') as f:\n","#     pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G428VVy75GsA"},"source":["### 1. 사용자 입력 문장을 토큰화하고 전체 리뷰 데이터에 추가"]},{"cell_type":"code","metadata":{"id":"9F2N2r5-Ffx9","executionInfo":{"status":"ok","timestamp":1626616188721,"user_tz":-540,"elapsed":281,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["def sentence_preprocessing(tokenized_doc_path, user_sentence):\n","  '''토큰화된 전체 리뷰 불러오기'''\n","  with open(tokenized_doc_path, 'rb') as f:\n","    result = pickle.load(f)\n","\n","  '''사용자 입력 문장 전처리'''\n","  '''규원님 전처리 라이브러리 사용하는 방식으로 코드 수정해야함'''\n","  user_sentence = user_sentence.replace(\"[^a-zA-Z]\", \" \")\n","  # 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n","  user_sentence = ' '.join([w for w in user_sentence.split() if len(w)>=3])\n","  # 전체 단어에 대한 소문자 변환\n","  user_sentence = user_sentence.lower()\n","  nltk.download('stopwords')\n","  # NLTK로부터 불용어 로드\n","  stop_words = stopwords.words('english') \n","  tokenized_doc = user_sentence.split() # 토큰화\n","  tokenized_doc = [item for item in tokenized_doc if item not in stop_words] # 불용어 제거\n","  nltk.download('wordnet')\n","  n = WordNetLemmatizer()\n","  tokenized_doc = [n.lemmatize(item) for item in tokenized_doc] # 표제어 추출\n","\n","  '''토큰화된 데이터에 사용자 문장 추가'''\n","  final_result = copy.deepcopy(result)\n","  final_result.append(tokenized_doc)\n","\n","  return final_result"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-duSEWxJxqKD"},"source":["### 2. 사전 훈련된 워드 임베딩 로드하여 단어 벡터 평균 계산"]},{"cell_type":"code","metadata":{"id":"RF9RrSwawPLe","executionInfo":{"status":"ok","timestamp":1626614822071,"user_tz":-540,"elapsed":252,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["# 단어 벡터 평균 구하기\n","def vectors(model_path, document_list):\n","    # 모델 로드\n","    from gensim.models import Word2Vec, KeyedVectors\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_path)\n","\n","    document_embedding_list = []\n","\n","    # 각 문서에 대해서\n","    for line in document_list:\n","        doc2vec = None\n","        count = 0\n","        for word in line:\n","            if word in word2vec_model.vocab:\n","                count += 1\n","                # 해당 문서에 있는 모든 단어들의 벡터값을 더한다.\n","                if doc2vec is None:\n","                    doc2vec = word2vec_model[word]\n","                else:\n","                    doc2vec = doc2vec + word2vec_model[word]\n","        \n","        if doc2vec is None:\n","            doc2vec = np.empty(100,)\n","            doc2vec[:] = 0\n","            document_embedding_list.append(doc2vec)\n","        else:\n","            # 단어 벡터를 모두 더한 벡터의 값을 문서 길이로 나눠준다.\n","            doc2vec = doc2vec / count\n","            document_embedding_list.append(doc2vec)\n","\n","    # 각 문서에 대한 문서 벡터 리스트를 리턴\n","    return document_embedding_list"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2GloCYBrx0t1"},"source":["### 3. 문서 간 유사도 계산\n","\n","향수 데이터에서는 전체 문서간의 코사인 유사도 매트릭스가 아닌 같은 라벨 내에서 사용자 입력문장과의 유사도 매트릭스를 구해야 함"]},{"cell_type":"code","metadata":{"id":"U7CLxH_R_vsZ","executionInfo":{"status":"ok","timestamp":1626616339064,"user_tz":-540,"elapsed":267,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["def recommendations(df_path, document_embedding_list):\n","\n","    df = pd.read_csv(df_path)\n","    df.drop('Unnamed: 0', axis=1, inplace=True)\n","\n","    # 다른 문서들과의 유사도 측정\n","    similarity = cosine_similarity([document_embedding_list[-1]], document_embedding_list[0:-1])\n","\n","    perfumes = df[['name', 'review']]\n","\n","    # 전체 cosine유사도 행렬에서 사용자 입력 문장과 가장 유사한 순으로 리뷰 정렬\n","    sim_scores = list(enumerate(similarity.reshape(-1,1)))\n","    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n","    sim_scores = sim_scores[1:10]\n","\n","    # 가장 유사한 리뷰 10개의 인덱스\n","    per_indices = [i[0] for i in sim_scores]\n","\n","    # 전체 데이터프레임에서 해당 인덱스의 행만 추출. 5개의 행을 가진다.\n","    recommend = df.iloc[per_indices].reset_index(drop=True)\n","\n","    top3_df = pd.DataFrame(columns=['name','similarity','review'])\n","\n","    # 데이터프레임으로부터 순차적으로 출력\n","    recommend_perfume = []\n","    for index, row in recommend.iterrows():\n","      if len(recommend_perfume)==3:\n","        break\n","      if row['name'] in recommend_perfume:\n","        continue\n","      else:\n","        recommend_perfume.append(row['name'])\n","        top3_df = top3_df.append({'name':row['name'], 'similarity':sim_scores[index][1], 'review':row['review']},ignore_index=True)\n","      print('Top {}'.format(len(recommend_perfume)))\n","      print('향수 명: ' ,row['name'])\n","      print('유사도: ',sim_scores[index][1])\n","      print('리뷰: ', row['review'])\n","      print()\n","      print()\n","    \n","    return top3_df"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EndXecEZ4W7w"},"source":["전체 실행"]},{"cell_type":"code","metadata":{"id":"n4QEJS5vERef","executionInfo":{"status":"ok","timestamp":1626615333621,"user_tz":-540,"elapsed":9,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["user_sentence = 'The guitarist of the band Sensual and sexy Wearing a shirt and ripped jeans Sweet and drowsy eyes He soaked in sweat in the heat of the stage'"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NT8CPdjEOTL","executionInfo":{"status":"ok","timestamp":1626616195074,"user_tz":-540,"elapsed":376,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["df_path = '/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/data/dataset_210626_215600.csv'\n","tokenized_doc_path = '/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/data/tokenized_doc.pickle'\n","model_path = '/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/model/w2v_10window'"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-vkgR5h4W4W","executionInfo":{"status":"ok","timestamp":1626616361181,"user_tz":-540,"elapsed":18620,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"6035772a-f9c1-4095-d83d-e2f9a7095228"},"source":["final_result = sentence_preprocessing(tokenized_doc_path, user_sentence)\n","document_embedding_list = vectors(model_path, final_result)\n","top3_df = recommendations(df_path, document_embedding_list)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","Top 1\n","향수 명:  Shalimar Eau de Parfum Guerlain for women\n","유사도:  [0.91948322]\n","리뷰:  Shalimar is hands down the sexiest, most seductive perfume a woman can smell of. Beautiful, stunning. Must be accompanied by a nice outfit and a pair of heels.\n","Hair in waves, perfectly painted lips..\n","Not for a gum chewing airhead whose thong is showing above her jeans.\n","\n","\n","Top 2\n","향수 명:  Narciso Rodriguez For Her Narciso Rodriguez for women\n","유사도:  [0.91844152]\n","리뷰:  This is certainly modern, and makes me smile.  I think of a well dressed women, who starts the evening making herself up with nice makeup, maybe from the Clinique counter.  She washes her hair with fancy shampoo and wears expensive leather boots.  Fall is over, winter is coming, and by midnight it is cold out, but the air is crisp and cleansing, she is only wearing a thin jacket. However the night is so invigorating that the heat of her skin keeps her warm.  This woman will be out in the city until after the bars close, seeing her friends first but perhaps meeting a man, walking home at 4 am, her skin is musky, her hair catches the scent of steely cold and smoke and frozen bare trees, her dress smells like her.  \n","The first time I tested this was on a strip.  It placed it on my dresser and went to bed a few hours later.  I woke up in the middle of the night and had to move the strip--it was suffocating the whole room and waking me up.  That is projection!!\n","\n","\n","Top 3\n","향수 명:  Fahrenheit Christian Dior for men\n","유사도:  [0.91645127]\n","리뷰:  This beast can be ultra male, leather, boots, bike, 3 day growth, tobacco and muscles\n","AND it can be feminine and sexy, like your girlfriend wearing your shirt like pj's over her naked body.\n","This beast is not to be overdosed, rather worn so the beholder gets that occasional wiff, that gets their attention and intrigues them.\n","Fahrenheit is unique and mysterious \n","Its certainly sexy. 😎\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"vYiAIZMBWVNs","executionInfo":{"status":"ok","timestamp":1626616462923,"user_tz":-540,"elapsed":331,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"ee9ee694-b87c-4736-9308-0871622eead9"},"source":["top3_df"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>similarity</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Shalimar Eau de Parfum Guerlain for women</td>\n","      <td>[0.9194832199600513]</td>\n","      <td>Shalimar is hands down the sexiest, most seduc...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Narciso Rodriguez For Her Narciso Rodriguez fo...</td>\n","      <td>[0.9184415210691973]</td>\n","      <td>This is certainly modern, and makes me smile. ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fahrenheit Christian Dior for men</td>\n","      <td>[0.9164512658515446]</td>\n","      <td>This beast can be ultra male, leather, boots, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                name  ...                                             review\n","0          Shalimar Eau de Parfum Guerlain for women  ...  Shalimar is hands down the sexiest, most seduc...\n","1  Narciso Rodriguez For Her Narciso Rodriguez fo...  ...  This is certainly modern, and makes me smile. ...\n","2                  Fahrenheit Christian Dior for men  ...  This beast can be ultra male, leather, boots, ...\n","\n","[3 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"Ii6PAFectFB6"},"source":["### 4. 키워드 추출 및 하이라이트 색상 지정\n","\n","reference code : https://towardsdatascience.com/textrank-for-keyword-extraction-by-python-c0bae21bcec0"]},{"cell_type":"code","metadata":{"id":"qm6bU7h8IL95","executionInfo":{"status":"ok","timestamp":1626618040851,"user_tz":-540,"elapsed":1125,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["class TextRank4Keyword():\n","  from collections import OrderedDict\n","  import numpy as np\n","  import spacy\n","  from spacy.lang.en.stop_words import STOP_WORDS\n","\n","  nlp = spacy.load('en_core_web_sm')\n","  \"\"\"Extract keywords from text\"\"\"\n","  \n","  def __init__(self):\n","    self.d = 0.85 # damping coefficient, usually is .85\n","    self.min_diff = 1e-5 # convergence threshold\n","    self.steps = 10 # iteration steps\n","    self.node_weight = None # save keywords and its weight\n","\n","  \n","  def set_stopwords(self, stopwords):  \n","    \"\"\"Set stop words\"\"\"\n","    for word in STOP_WORDS.union(set(stopwords)):\n","        lexeme = nlp.vocab[word]\n","        lexeme.is_stop = True\n","  \n","  def sentence_segment(self, doc, candidate_pos, lower):\n","    \"\"\"Store those words only in cadidate_pos\"\"\"\n","    sentences = []\n","    for sent in doc.sents:\n","        selected_words = []\n","        for token in sent:\n","            # Store words only with cadidate POS tag\n","            if token.pos_ in candidate_pos and token.is_stop is False:\n","                if lower is True:\n","                    selected_words.append(token.text.lower())\n","                else:\n","                    selected_words.append(token.text)\n","        sentences.append(selected_words)\n","    return sentences\n","      \n","  def get_vocab(self, sentences):\n","    \"\"\"Get all tokens\"\"\"\n","    vocab = OrderedDict()\n","    i = 0\n","    for sentence in sentences:\n","        for word in sentence:\n","            if word not in vocab:\n","                vocab[word] = i\n","                i += 1\n","    return vocab\n","  \n","  def get_token_pairs(self, window_size, sentences):\n","    \"\"\"Build token_pairs from windows in sentences\"\"\"\n","    token_pairs = list()\n","    for sentence in sentences:\n","        for i, word in enumerate(sentence):\n","            for j in range(i+1, i+window_size):\n","                if j >= len(sentence):\n","                    break\n","                pair = (word, sentence[j])\n","                if pair not in token_pairs:\n","                    token_pairs.append(pair)\n","    return token_pairs\n","      \n","  def symmetrize(self, a):\n","    return a + a.T - np.diag(a.diagonal())\n","  \n","  def get_matrix(self, vocab, token_pairs):\n","    \"\"\"Get normalized matrix\"\"\"\n","    # Build matrix\n","    vocab_size = len(vocab)\n","    g = np.zeros((vocab_size, vocab_size), dtype='float')\n","    for word1, word2 in token_pairs:\n","        i, j = vocab[word1], vocab[word2]\n","        g[i][j] = 1\n","        \n","    # Get Symmeric matrix\n","    g = self.symmetrize(g)\n","    \n","    # Normalize matrix by column\n","    norm = np.sum(g, axis=0)\n","    g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n","    \n","    return g_norm\n","\n","  \n","  def get_keywords(self, number=10):\n","    \"\"\"Return top number keywords\"\"\"\n","    node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n","    dic = dict()\n","    for i, (key, value) in enumerate(node_weight.items()):\n","        dic[key]=value\n","        if i > number:\n","            break\n","    return dic\n","      \n","      \n","  def analyze(self, text, \n","            candidate_pos=['NOUN', 'PROPN'], \n","            window_size=4, lower=False, stopwords=list()):\n","    \"\"\"Main function to analyze text\"\"\"\n","    \n","    # Set stop words\n","    self.set_stopwords(stopwords)\n","    \n","    # Pare text by spaCy\n","    doc = nlp(text)\n","    \n","    # Filter sentences\n","    sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n","    \n","    # Build vocabulary\n","    vocab = self.get_vocab(sentences)\n","    \n","    # Get token_pairs from windows\n","    token_pairs = self.get_token_pairs(window_size, sentences)\n","    \n","    # Get normalized matrix\n","    g = self.get_matrix(vocab, token_pairs)\n","    \n","    # Initionlization for weight(pagerank value)\n","    pr = np.array([1] * len(vocab))\n","    \n","    # Iteration\n","    previous_pr = 0\n","    for epoch in range(self.steps):\n","        pr = (1-self.d) + self.d * np.dot(g, pr)\n","        if abs(previous_pr - sum(pr))  < self.min_diff:\n","            break\n","        else:\n","            previous_pr = sum(pr)\n","\n","    # Get weight for each node\n","    node_weight = dict()\n","    for word, index in vocab.items():\n","        node_weight[word] = pr[index]\n","    \n","    self.node_weight = node_weight"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4Tic42DIOww","executionInfo":{"status":"ok","timestamp":1626619858674,"user_tz":-540,"elapsed":279,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["def keyword_highlighter(user_sentence, top3_df, model_path):\n","  \"\"\"사용자 입력문장과 추천문장에서 키워드 추출\"\"\"\n","  tr4w = TextRank4Keyword()\n","\n","  from gensim.models import Word2Vec, KeyedVectors\n","  word2vec_model = KeyedVectors.load_word2vec_format(model_path)\n","\n","  # 사용자 입력 문장의 키워드 추출\n","  user_keyword = []\n","  tr4w.analyze(user_sentence, candidate_pos = ['NOUN', 'PROPN', 'ADJ'], window_size=5, lower=False)\n","  user_keyword = list(tr4w.get_keywords(100).keys())\n","  user_keyword = [word for word in user_keyword if word in word2vec_model.vocab] # 임베딩 벡터에 없는 단어는 제외\n","  print('사용자 문장에서 추출된 키워드 : ' ,user_keyword)\n","\n","  # 추천 향수 리뷰의 키워드 추출하여 dataframe에 cloumn으로 저장\n","  top3_keyword = []\n","  for i in range(0,len(top3_df)):\n","    tr4w.analyze(top3_df['review'][i], candidate_pos = ['NOUN', 'PROPN', 'ADJ'], window_size=5, lower=False)\n","    keywords = list(tr4w.get_keywords(100).keys())\n","    keywords = [word for word in keywords if word in word2vec_model.vocab] # 임베딩 벡터에 없는 단어는 제외\n","    top3_keyword.append(keywords)\n","\n","  top3_df['keywords']=top3_keyword\n","\n","  \"\"\"하이라이트 컬러 할당\"\"\"\n","  import random\n","  import colorsys\n","\n","  custom_palette = []\n","  for i in range(0, len(user_keyword)):\n","    r = random.random()\n","    h,s,l = r, 1, 0.82\n","    r,g,b = colorsys.hls_to_rgb(h, l, s)\n","    r,g,b = int(r*255),int(g*255),int(b*255)\n","    color = '#%02x%02x%02x' % (r,g,b)\n","    custom_palette.append(color)\n","  \n","  # user keyword에 랜덤 파스텔 컬러 할당\n","  user_dict = {word : custom_palette[i] for i,word in enumerate(user_keyword)}\n","  user_dict\n","\n","  # 추천 리뷰 keyword에 컬러 할당\n","  color_list = []\n","  for i in range(0, len(top3_df)):\n","    top3_dict = dict.fromkeys(top3_df['keywords'][i])\n","    index = 0\n","    for uw in user_dict.keys():\n","      for tw in top3_dict.keys():\n","        # 임계값 0.6로 잡아봄\n","        if word2vec_model.similarity(uw, tw) > 0.65:\n","          # 컬러 할당이 안되어있는 상태라면 처음 값 넣어줌\n","          if top3_dict[tw] is None:\n","            top3_dict[tw] = list(user_dict.items())[index]\n","          # 컬러 할당이 되어있는 상태라면 유사도 더 높은 컬러로 넣어줌\n","          elif word2vec_model.similarity(uw, tw) > word2vec_model.similarity(top3_dict[tw][0], tw): #이전 user word와 비교\n","            top3_dict[tw] = list(user_dict.items())[index]\n","      index+=1\n","    color_list.append(top3_dict)\n","\n","  # 데이터 프레임에 색상 정보 추가\n","  top3_df['colors']=color_list\n","\n","  return top3_df"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X596d4Gsu9EG","executionInfo":{"status":"ok","timestamp":1626619862435,"user_tz":-540,"elapsed":3442,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"dc224668-b7dd-4ace-9251-112ca5eb5d8d"},"source":["top3_df = keyword_highlighter(user_sentence,top3_df, model_path)"],"execution_count":127,"outputs":[{"output_type":"stream","text":["사용자 문장에서 추출된 키워드 :  ['shirt', 'sexy', 'jeans', 'sweat', 'heat', 'stage', 'band', 'guitarist', 'eyes']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QAgJsmIkGbf","executionInfo":{"status":"ok","timestamp":1626619862438,"user_tz":-540,"elapsed":39,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"399976e5-396a-4d7f-8292-37a10ee7a6c6"},"source":["for i in top3_df.colors:\n","  print(i)"],"execution_count":128,"outputs":[{"output_type":"stream","text":["{'gum': None, 'chewing': ('guitarist', '#a3aefe'), 'lips': ('guitarist', '#a3aefe'), 'airhead': ('guitarist', '#a3aefe'), 'hands': ('guitarist', '#a3aefe'), 'sexiest': None, 'seductive': ('sexy', '#fea3d9'), 'perfume': None, 'stunning': None, 'nice': None, 'outfit': ('jeans', '#a3a6fe'), 'pair': None, 'waves': ('guitarist', '#a3aefe'), 'thong': ('guitarist', '#a3aefe'), 'woman': None, 'jeans': ('jeans', '#a3a6fe')}\n","{'cold': None, 'hair': ('shirt', '#a3fedc'), 'skin': None, 'night': ('jeans', '#a3a6fe'), 'air': None, 'man': None, 'musky': None, 'scent': None, 'strip': None, 'crisp': None, 'evening': ('jeans', '#a3a6fe'), 'nice': None, 'makeup': None, 'friends': None, 'dresser': ('eyes', '#c9a3fe'), 'bed': None, 'hours': None, 'cleansing': ('guitarist', '#a3aefe'), 'midnight': None, 'middle': None, 'room': None, 'fancy': None, 'shampoo': None, 'expensive': None, 'leather': None, 'women': ('eyes', '#c9a3fe'), 'counter': None, 'bare': None, 'thin': None, 'winter': None, 'city': None, 'boots': ('guitarist', '#a3aefe'), 'trees': ('guitarist', '#a3aefe'), 'jacket': None, 'heat': ('heat', '#feb9a3'), 'warm': None, 'woman': None, 'dress': ('jeans', '#a3a6fe'), 'time': None, 'modern': None, 'projection': None}\n","{'sexy': ('sexy', '#fea3d9'), 'boots': ('guitarist', '#a3aefe'), 'bike': ('jeans', '#a3a6fe'), 'leather': None, 'day': None, 'girlfriend': None, 'shirt': ('shirt', '#a3fedc'), 'male': None, 'beholder': ('eyes', '#c9a3fe'), 'occasional': None, 'wiff': ('eyes', '#c9a3fe'), 'attention': None, 'growth': ('guitarist', '#a3aefe'), 'naked': None, 'beast': None, 'ultra': ('guitarist', '#a3aefe'), 'tobacco': None, 'feminine': None, 'unique': None, 'mysterious': ('sexy', '#fea3d9'), 'body': None, 'worn': ('jeans', '#a3a6fe')}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"4ZrnBQgLvrF1","executionInfo":{"status":"ok","timestamp":1626619652974,"user_tz":-540,"elapsed":357,"user":{"displayName":"진현영","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"92f00d36-7ccc-40a6-e496-043f3de95677"},"source":["top3_df"],"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>similarity</th>\n","      <th>review</th>\n","      <th>keywords</th>\n","      <th>colors</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Shalimar Eau de Parfum Guerlain for women</td>\n","      <td>[0.9194832199600513]</td>\n","      <td>Shalimar is hands down the sexiest, most seduc...</td>\n","      <td>[gum, chewing, lips, airhead, hands, sexiest, ...</td>\n","      <td>{'gum': None, 'chewing': ('guitarist', '#fea3a...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Narciso Rodriguez For Her Narciso Rodriguez fo...</td>\n","      <td>[0.9184415210691973]</td>\n","      <td>This is certainly modern, and makes me smile. ...</td>\n","      <td>[cold, hair, skin, night, air, man, musky, sce...</td>\n","      <td>{'cold': None, 'hair': None, 'skin': None, 'ni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fahrenheit Christian Dior for men</td>\n","      <td>[0.9164512658515446]</td>\n","      <td>This beast can be ultra male, leather, boots, ...</td>\n","      <td>[sexy, boots, bike, leather, day, girlfriend, ...</td>\n","      <td>{'sexy': ('sexy', '#b7a3fe'), 'boots': ('guita...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                name  ...                                             colors\n","0          Shalimar Eau de Parfum Guerlain for women  ...  {'gum': None, 'chewing': ('guitarist', '#fea3a...\n","1  Narciso Rodriguez For Her Narciso Rodriguez fo...  ...  {'cold': None, 'hair': None, 'skin': None, 'ni...\n","2                  Fahrenheit Christian Dior for men  ...  {'sexy': ('sexy', '#b7a3fe'), 'boots': ('guita...\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":119}]}]}