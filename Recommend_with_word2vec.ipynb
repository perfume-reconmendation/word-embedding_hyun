{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Recommend_with_word2vec.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MLqzJm_Svmt2"},"source":["## ë¬¸ì„œ ë²¡í„°ë¥¼ ì´ìš©í•œ ì¶”ì²œ ì‹œìŠ¤í…œ(Recommendation System using Document Embedding)"]},{"cell_type":"markdown","metadata":{"id":"cNKwcG3C2cDR"},"source":["## Library Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7ZHm5QFvAsC","executionInfo":{"status":"ok","timestamp":1626614545655,"user_tz":-540,"elapsed":18776,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"379e8743-ac2a-48b6-cb3c-5dbe15d51bd4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=False)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nhJ7dKUqgNb9","executionInfo":{"status":"ok","timestamp":1626619715664,"user_tz":-540,"elapsed":348,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics.pairwise import cosine_similarity\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import re\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","import copy\n","import pickle\n","from collections import OrderedDict\n","import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS"],"execution_count":120,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HmG_T9lX1xfP"},"source":["ì „ì²´ ë¦¬ë·° ë°ì´í„°ì˜ stringí˜•íƒœë¥¼ í† í°í™”ëœ corpusë¡œ ì „ì²˜ë¦¬ í•˜ëŠ” ê³¼ì •\n","\n","(1íšŒë§Œ ìˆ˜í–‰ í›„ ê²°ê³¼ë¥¼ pickleë¡œ ì €ì¥í•˜ê³  ê·¸ í›„ì—ëŠ” í•´ë‹¹ ê²½ë¡œë¥¼ ì¸ìë¡œ ì…ë ¥í•˜ì—¬ í˜¸ì¶œ)"]},{"cell_type":"code","metadata":{"id":"ofz4bJyxEhG5","executionInfo":{"status":"ok","timestamp":1626615661418,"user_tz":-540,"elapsed":321,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["# df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/data/dataset_210626_215600.csv')\n","# df.drop('Unnamed: 0', axis=1, inplace=True)\n","# sent_text = df['lemmatizated']\n","# # ì›ë³¸ ë°ì´í„°ì˜ strë¶€ë¶„ì„ ì „ì²˜ë¦¬\n","# nltk.download('punkt')\n","# normalized_text = []\n","# for string in sent_text:\n","#     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","#     tokens = ' '.join([w for w in tokens.split() if len(w)>=3])\n","#     normalized_text.append(tokens)\n","# result = []\n","# result = [word_tokenize(sentence) for sentence in normalized_text]\n","\n","# corpus_dir = '/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/data/tokenized_doc.pickle'\n","\n","# # save\n","# with open(corpus_dir, 'wb') as f:\n","#     pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G428VVy75GsA"},"source":["### 1. ì‚¬ìš©ì ì…ë ¥ ë¬¸ì¥ì„ í† í°í™”í•˜ê³  ì „ì²´ ë¦¬ë·° ë°ì´í„°ì— ì¶”ê°€"]},{"cell_type":"code","metadata":{"id":"9F2N2r5-Ffx9","executionInfo":{"status":"ok","timestamp":1626616188721,"user_tz":-540,"elapsed":281,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["def sentence_preprocessing(tokenized_doc_path, user_sentence):\n","  '''í† í°í™”ëœ ì „ì²´ ë¦¬ë·° ë¶ˆëŸ¬ì˜¤ê¸°'''\n","  with open(tokenized_doc_path, 'rb') as f:\n","    result = pickle.load(f)\n","\n","  '''ì‚¬ìš©ì ì…ë ¥ ë¬¸ì¥ ì „ì²˜ë¦¬'''\n","  '''ê·œì›ë‹˜ ì „ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì½”ë“œ ìˆ˜ì •í•´ì•¼í•¨'''\n","  user_sentence = user_sentence.replace(\"[^a-zA-Z]\", \" \")\n","  # ê¸¸ì´ê°€ 3ì´í•˜ì¸ ë‹¨ì–´ëŠ” ì œê±° (ê¸¸ì´ê°€ ì§§ì€ ë‹¨ì–´ ì œê±°)\n","  user_sentence = ' '.join([w for w in user_sentence.split() if len(w)>=3])\n","  # ì „ì²´ ë‹¨ì–´ì— ëŒ€í•œ ì†Œë¬¸ì ë³€í™˜\n","  user_sentence = user_sentence.lower()\n","  nltk.download('stopwords')\n","  # NLTKë¡œë¶€í„° ë¶ˆìš©ì–´ ë¡œë“œ\n","  stop_words = stopwords.words('english') \n","  tokenized_doc = user_sentence.split() # í† í°í™”\n","  tokenized_doc = [item for item in tokenized_doc if item not in stop_words] # ë¶ˆìš©ì–´ ì œê±°\n","  nltk.download('wordnet')\n","  n = WordNetLemmatizer()\n","  tokenized_doc = [n.lemmatize(item) for item in tokenized_doc] # í‘œì œì–´ ì¶”ì¶œ\n","\n","  '''í† í°í™”ëœ ë°ì´í„°ì— ì‚¬ìš©ì ë¬¸ì¥ ì¶”ê°€'''\n","  final_result = copy.deepcopy(result)\n","  final_result.append(tokenized_doc)\n","\n","  return final_result"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-duSEWxJxqKD"},"source":["### 2. ì‚¬ì „ í›ˆë ¨ëœ ì›Œë“œ ì„ë² ë”© ë¡œë“œí•˜ì—¬ ë‹¨ì–´ ë²¡í„° í‰ê·  ê³„ì‚°"]},{"cell_type":"code","metadata":{"id":"RF9RrSwawPLe","executionInfo":{"status":"ok","timestamp":1626614822071,"user_tz":-540,"elapsed":252,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["# ë‹¨ì–´ ë²¡í„° í‰ê·  êµ¬í•˜ê¸°\n","def vectors(model_path, document_list):\n","    # ëª¨ë¸ ë¡œë“œ\n","    from gensim.models import Word2Vec, KeyedVectors\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_path)\n","\n","    document_embedding_list = []\n","\n","    # ê° ë¬¸ì„œì— ëŒ€í•´ì„œ\n","    for line in document_list:\n","        doc2vec = None\n","        count = 0\n","        for word in line:\n","            if word in word2vec_model.vocab:\n","                count += 1\n","                # í•´ë‹¹ ë¬¸ì„œì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ë“¤ì˜ ë²¡í„°ê°’ì„ ë”í•œë‹¤.\n","                if doc2vec is None:\n","                    doc2vec = word2vec_model[word]\n","                else:\n","                    doc2vec = doc2vec + word2vec_model[word]\n","        \n","        if doc2vec is None:\n","            doc2vec = np.empty(100,)\n","            doc2vec[:] = 0\n","            document_embedding_list.append(doc2vec)\n","        else:\n","            # ë‹¨ì–´ ë²¡í„°ë¥¼ ëª¨ë‘ ë”í•œ ë²¡í„°ì˜ ê°’ì„ ë¬¸ì„œ ê¸¸ì´ë¡œ ë‚˜ëˆ ì¤€ë‹¤.\n","            doc2vec = doc2vec / count\n","            document_embedding_list.append(doc2vec)\n","\n","    # ê° ë¬¸ì„œì— ëŒ€í•œ ë¬¸ì„œ ë²¡í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë¦¬í„´\n","    return document_embedding_list"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2GloCYBrx0t1"},"source":["### 3. ë¬¸ì„œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°\n","\n","í–¥ìˆ˜ ë°ì´í„°ì—ì„œëŠ” ì „ì²´ ë¬¸ì„œê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ê°€ ì•„ë‹Œ ê°™ì€ ë¼ë²¨ ë‚´ì—ì„œ ì‚¬ìš©ì ì…ë ¥ë¬¸ì¥ê³¼ì˜ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ êµ¬í•´ì•¼ í•¨"]},{"cell_type":"code","metadata":{"id":"U7CLxH_R_vsZ","executionInfo":{"status":"ok","timestamp":1626616339064,"user_tz":-540,"elapsed":267,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["def recommendations(df_path, document_embedding_list):\n","\n","    df = pd.read_csv(df_path)\n","    df.drop('Unnamed: 0', axis=1, inplace=True)\n","\n","    # ë‹¤ë¥¸ ë¬¸ì„œë“¤ê³¼ì˜ ìœ ì‚¬ë„ ì¸¡ì •\n","    similarity = cosine_similarity([document_embedding_list[-1]], document_embedding_list[0:-1])\n","\n","    perfumes = df[['name', 'review']]\n","\n","    # ì „ì²´ cosineìœ ì‚¬ë„ í–‰ë ¬ì—ì„œ ì‚¬ìš©ì ì…ë ¥ ë¬¸ì¥ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ìˆœìœ¼ë¡œ ë¦¬ë·° ì •ë ¬\n","    sim_scores = list(enumerate(similarity.reshape(-1,1)))\n","    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n","    sim_scores = sim_scores[1:10]\n","\n","    # ê°€ì¥ ìœ ì‚¬í•œ ë¦¬ë·° 10ê°œì˜ ì¸ë±ìŠ¤\n","    per_indices = [i[0] for i in sim_scores]\n","\n","    # ì „ì²´ ë°ì´í„°í”„ë ˆì„ì—ì„œ í•´ë‹¹ ì¸ë±ìŠ¤ì˜ í–‰ë§Œ ì¶”ì¶œ. 5ê°œì˜ í–‰ì„ ê°€ì§„ë‹¤.\n","    recommend = df.iloc[per_indices].reset_index(drop=True)\n","\n","    top3_df = pd.DataFrame(columns=['name','similarity','review'])\n","\n","    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥\n","    recommend_perfume = []\n","    for index, row in recommend.iterrows():\n","      if len(recommend_perfume)==3:\n","        break\n","      if row['name'] in recommend_perfume:\n","        continue\n","      else:\n","        recommend_perfume.append(row['name'])\n","        top3_df = top3_df.append({'name':row['name'], 'similarity':sim_scores[index][1], 'review':row['review']},ignore_index=True)\n","      print('Top {}'.format(len(recommend_perfume)))\n","      print('í–¥ìˆ˜ ëª…: ' ,row['name'])\n","      print('ìœ ì‚¬ë„: ',sim_scores[index][1])\n","      print('ë¦¬ë·°: ', row['review'])\n","      print()\n","      print()\n","    \n","    return top3_df"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EndXecEZ4W7w"},"source":["ì „ì²´ ì‹¤í–‰"]},{"cell_type":"code","metadata":{"id":"n4QEJS5vERef","executionInfo":{"status":"ok","timestamp":1626615333621,"user_tz":-540,"elapsed":9,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["user_sentence = 'The guitarist of the band Sensual and sexy Wearing a shirt and ripped jeans Sweet and drowsy eyes He soaked in sweat in the heat of the stage'"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NT8CPdjEOTL","executionInfo":{"status":"ok","timestamp":1626616195074,"user_tz":-540,"elapsed":376,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["df_path = '/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/data/dataset_210626_215600.csv'\n","tokenized_doc_path = '/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/data/tokenized_doc.pickle'\n","model_path = '/content/gdrive/MyDrive/Colab Notebooks/deeplearning_NLP/perfume/word embedding_hyun/model/w2v_10window'"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-vkgR5h4W4W","executionInfo":{"status":"ok","timestamp":1626616361181,"user_tz":-540,"elapsed":18620,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"6035772a-f9c1-4095-d83d-e2f9a7095228"},"source":["final_result = sentence_preprocessing(tokenized_doc_path, user_sentence)\n","document_embedding_list = vectors(model_path, final_result)\n","top3_df = recommendations(df_path, document_embedding_list)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","Top 1\n","í–¥ìˆ˜ ëª…:  Shalimar Eau de Parfum Guerlain for women\n","ìœ ì‚¬ë„:  [0.91948322]\n","ë¦¬ë·°:  Shalimar is hands down the sexiest, most seductive perfume a woman can smell of. Beautiful, stunning. Must be accompanied by a nice outfit and a pair of heels.\n","Hair in waves, perfectly painted lips..\n","Not for a gum chewing airhead whose thong is showing above her jeans.\n","\n","\n","Top 2\n","í–¥ìˆ˜ ëª…:  Narciso Rodriguez For Her Narciso Rodriguez for women\n","ìœ ì‚¬ë„:  [0.91844152]\n","ë¦¬ë·°:  This is certainly modern, and makes me smile.  I think of a well dressed women, who starts the evening making herself up with nice makeup, maybe from the Clinique counter.  She washes her hair with fancy shampoo and wears expensive leather boots.  Fall is over, winter is coming, and by midnight it is cold out, but the air is crisp and cleansing, she is only wearing a thin jacket. However the night is so invigorating that the heat of her skin keeps her warm.  This woman will be out in the city until after the bars close, seeing her friends first but perhaps meeting a man, walking home at 4 am, her skin is musky, her hair catches the scent of steely cold and smoke and frozen bare trees, her dress smells like her.  \n","The first time I tested this was on a strip.  It placed it on my dresser and went to bed a few hours later.  I woke up in the middle of the night and had to move the strip--it was suffocating the whole room and waking me up.  That is projection!!\n","\n","\n","Top 3\n","í–¥ìˆ˜ ëª…:  Fahrenheit Christian Dior for men\n","ìœ ì‚¬ë„:  [0.91645127]\n","ë¦¬ë·°:  This beast can be ultra male, leather, boots, bike, 3 day growth, tobacco and muscles\n","AND it can be feminine and sexy, like your girlfriend wearing your shirt like pj's over her naked body.\n","This beast is not to be overdosed, rather worn so the beholder gets that occasional wiff, that gets their attention and intrigues them.\n","Fahrenheit is unique and mysterious \n","Its certainly sexy. ğŸ˜\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"vYiAIZMBWVNs","executionInfo":{"status":"ok","timestamp":1626616462923,"user_tz":-540,"elapsed":331,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"ee9ee694-b87c-4736-9308-0871622eead9"},"source":["top3_df"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>similarity</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Shalimar Eau de Parfum Guerlain for women</td>\n","      <td>[0.9194832199600513]</td>\n","      <td>Shalimar is hands down the sexiest, most seduc...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Narciso Rodriguez For Her Narciso Rodriguez fo...</td>\n","      <td>[0.9184415210691973]</td>\n","      <td>This is certainly modern, and makes me smile. ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fahrenheit Christian Dior for men</td>\n","      <td>[0.9164512658515446]</td>\n","      <td>This beast can be ultra male, leather, boots, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                name  ...                                             review\n","0          Shalimar Eau de Parfum Guerlain for women  ...  Shalimar is hands down the sexiest, most seduc...\n","1  Narciso Rodriguez For Her Narciso Rodriguez fo...  ...  This is certainly modern, and makes me smile. ...\n","2                  Fahrenheit Christian Dior for men  ...  This beast can be ultra male, leather, boots, ...\n","\n","[3 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"Ii6PAFectFB6"},"source":["### 4. í‚¤ì›Œë“œ ì¶”ì¶œ ë° í•˜ì´ë¼ì´íŠ¸ ìƒ‰ìƒ ì§€ì •\n","\n","reference code : https://towardsdatascience.com/textrank-for-keyword-extraction-by-python-c0bae21bcec0"]},{"cell_type":"code","metadata":{"id":"qm6bU7h8IL95","executionInfo":{"status":"ok","timestamp":1626618040851,"user_tz":-540,"elapsed":1125,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["class TextRank4Keyword():\n","  from collections import OrderedDict\n","  import numpy as np\n","  import spacy\n","  from spacy.lang.en.stop_words import STOP_WORDS\n","\n","  nlp = spacy.load('en_core_web_sm')\n","  \"\"\"Extract keywords from text\"\"\"\n","  \n","  def __init__(self):\n","    self.d = 0.85 # damping coefficient, usually is .85\n","    self.min_diff = 1e-5 # convergence threshold\n","    self.steps = 10 # iteration steps\n","    self.node_weight = None # save keywords and its weight\n","\n","  \n","  def set_stopwords(self, stopwords):  \n","    \"\"\"Set stop words\"\"\"\n","    for word in STOP_WORDS.union(set(stopwords)):\n","        lexeme = nlp.vocab[word]\n","        lexeme.is_stop = True\n","  \n","  def sentence_segment(self, doc, candidate_pos, lower):\n","    \"\"\"Store those words only in cadidate_pos\"\"\"\n","    sentences = []\n","    for sent in doc.sents:\n","        selected_words = []\n","        for token in sent:\n","            # Store words only with cadidate POS tag\n","            if token.pos_ in candidate_pos and token.is_stop is False:\n","                if lower is True:\n","                    selected_words.append(token.text.lower())\n","                else:\n","                    selected_words.append(token.text)\n","        sentences.append(selected_words)\n","    return sentences\n","      \n","  def get_vocab(self, sentences):\n","    \"\"\"Get all tokens\"\"\"\n","    vocab = OrderedDict()\n","    i = 0\n","    for sentence in sentences:\n","        for word in sentence:\n","            if word not in vocab:\n","                vocab[word] = i\n","                i += 1\n","    return vocab\n","  \n","  def get_token_pairs(self, window_size, sentences):\n","    \"\"\"Build token_pairs from windows in sentences\"\"\"\n","    token_pairs = list()\n","    for sentence in sentences:\n","        for i, word in enumerate(sentence):\n","            for j in range(i+1, i+window_size):\n","                if j >= len(sentence):\n","                    break\n","                pair = (word, sentence[j])\n","                if pair not in token_pairs:\n","                    token_pairs.append(pair)\n","    return token_pairs\n","      \n","  def symmetrize(self, a):\n","    return a + a.T - np.diag(a.diagonal())\n","  \n","  def get_matrix(self, vocab, token_pairs):\n","    \"\"\"Get normalized matrix\"\"\"\n","    # Build matrix\n","    vocab_size = len(vocab)\n","    g = np.zeros((vocab_size, vocab_size), dtype='float')\n","    for word1, word2 in token_pairs:\n","        i, j = vocab[word1], vocab[word2]\n","        g[i][j] = 1\n","        \n","    # Get Symmeric matrix\n","    g = self.symmetrize(g)\n","    \n","    # Normalize matrix by column\n","    norm = np.sum(g, axis=0)\n","    g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n","    \n","    return g_norm\n","\n","  \n","  def get_keywords(self, number=10):\n","    \"\"\"Return top number keywords\"\"\"\n","    node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n","    dic = dict()\n","    for i, (key, value) in enumerate(node_weight.items()):\n","        dic[key]=value\n","        if i > number:\n","            break\n","    return dic\n","      \n","      \n","  def analyze(self, text, \n","            candidate_pos=['NOUN', 'PROPN'], \n","            window_size=4, lower=False, stopwords=list()):\n","    \"\"\"Main function to analyze text\"\"\"\n","    \n","    # Set stop words\n","    self.set_stopwords(stopwords)\n","    \n","    # Pare text by spaCy\n","    doc = nlp(text)\n","    \n","    # Filter sentences\n","    sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n","    \n","    # Build vocabulary\n","    vocab = self.get_vocab(sentences)\n","    \n","    # Get token_pairs from windows\n","    token_pairs = self.get_token_pairs(window_size, sentences)\n","    \n","    # Get normalized matrix\n","    g = self.get_matrix(vocab, token_pairs)\n","    \n","    # Initionlization for weight(pagerank value)\n","    pr = np.array([1] * len(vocab))\n","    \n","    # Iteration\n","    previous_pr = 0\n","    for epoch in range(self.steps):\n","        pr = (1-self.d) + self.d * np.dot(g, pr)\n","        if abs(previous_pr - sum(pr))  < self.min_diff:\n","            break\n","        else:\n","            previous_pr = sum(pr)\n","\n","    # Get weight for each node\n","    node_weight = dict()\n","    for word, index in vocab.items():\n","        node_weight[word] = pr[index]\n","    \n","    self.node_weight = node_weight"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4Tic42DIOww","executionInfo":{"status":"ok","timestamp":1626619858674,"user_tz":-540,"elapsed":279,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}}},"source":["def keyword_highlighter(user_sentence, top3_df, model_path):\n","  \"\"\"ì‚¬ìš©ì ì…ë ¥ë¬¸ì¥ê³¼ ì¶”ì²œë¬¸ì¥ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ\"\"\"\n","  tr4w = TextRank4Keyword()\n","\n","  from gensim.models import Word2Vec, KeyedVectors\n","  word2vec_model = KeyedVectors.load_word2vec_format(model_path)\n","\n","  # ì‚¬ìš©ì ì…ë ¥ ë¬¸ì¥ì˜ í‚¤ì›Œë“œ ì¶”ì¶œ\n","  user_keyword = []\n","  tr4w.analyze(user_sentence, candidate_pos = ['NOUN', 'PROPN', 'ADJ'], window_size=5, lower=False)\n","  user_keyword = list(tr4w.get_keywords(100).keys())\n","  user_keyword = [word for word in user_keyword if word in word2vec_model.vocab] # ì„ë² ë”© ë²¡í„°ì— ì—†ëŠ” ë‹¨ì–´ëŠ” ì œì™¸\n","  print('ì‚¬ìš©ì ë¬¸ì¥ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œ : ' ,user_keyword)\n","\n","  # ì¶”ì²œ í–¥ìˆ˜ ë¦¬ë·°ì˜ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ dataframeì— cloumnìœ¼ë¡œ ì €ì¥\n","  top3_keyword = []\n","  for i in range(0,len(top3_df)):\n","    tr4w.analyze(top3_df['review'][i], candidate_pos = ['NOUN', 'PROPN', 'ADJ'], window_size=5, lower=False)\n","    keywords = list(tr4w.get_keywords(100).keys())\n","    keywords = [word for word in keywords if word in word2vec_model.vocab] # ì„ë² ë”© ë²¡í„°ì— ì—†ëŠ” ë‹¨ì–´ëŠ” ì œì™¸\n","    top3_keyword.append(keywords)\n","\n","  top3_df['keywords']=top3_keyword\n","\n","  \"\"\"í•˜ì´ë¼ì´íŠ¸ ì»¬ëŸ¬ í• ë‹¹\"\"\"\n","  import random\n","  import colorsys\n","\n","  custom_palette = []\n","  for i in range(0, len(user_keyword)):\n","    r = random.random()\n","    h,s,l = r, 1, 0.82\n","    r,g,b = colorsys.hls_to_rgb(h, l, s)\n","    r,g,b = int(r*255),int(g*255),int(b*255)\n","    color = '#%02x%02x%02x' % (r,g,b)\n","    custom_palette.append(color)\n","  \n","  # user keywordì— ëœë¤ íŒŒìŠ¤í…” ì»¬ëŸ¬ í• ë‹¹\n","  user_dict = {word : custom_palette[i] for i,word in enumerate(user_keyword)}\n","  user_dict\n","\n","  # ì¶”ì²œ ë¦¬ë·° keywordì— ì»¬ëŸ¬ í• ë‹¹\n","  color_list = []\n","  for i in range(0, len(top3_df)):\n","    top3_dict = dict.fromkeys(top3_df['keywords'][i])\n","    index = 0\n","    for uw in user_dict.keys():\n","      for tw in top3_dict.keys():\n","        # ì„ê³„ê°’ 0.6ë¡œ ì¡ì•„ë´„\n","        if word2vec_model.similarity(uw, tw) > 0.65:\n","          # ì»¬ëŸ¬ í• ë‹¹ì´ ì•ˆë˜ì–´ìˆëŠ” ìƒíƒœë¼ë©´ ì²˜ìŒ ê°’ ë„£ì–´ì¤Œ\n","          if top3_dict[tw] is None:\n","            top3_dict[tw] = list(user_dict.items())[index]\n","          # ì»¬ëŸ¬ í• ë‹¹ì´ ë˜ì–´ìˆëŠ” ìƒíƒœë¼ë©´ ìœ ì‚¬ë„ ë” ë†’ì€ ì»¬ëŸ¬ë¡œ ë„£ì–´ì¤Œ\n","          elif word2vec_model.similarity(uw, tw) > word2vec_model.similarity(top3_dict[tw][0], tw): #ì´ì „ user wordì™€ ë¹„êµ\n","            top3_dict[tw] = list(user_dict.items())[index]\n","      index+=1\n","    color_list.append(top3_dict)\n","\n","  # ë°ì´í„° í”„ë ˆì„ì— ìƒ‰ìƒ ì •ë³´ ì¶”ê°€\n","  top3_df['colors']=color_list\n","\n","  return top3_df"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X596d4Gsu9EG","executionInfo":{"status":"ok","timestamp":1626619862435,"user_tz":-540,"elapsed":3442,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"dc224668-b7dd-4ace-9251-112ca5eb5d8d"},"source":["top3_df = keyword_highlighter(user_sentence,top3_df, model_path)"],"execution_count":127,"outputs":[{"output_type":"stream","text":["ì‚¬ìš©ì ë¬¸ì¥ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œ :  ['shirt', 'sexy', 'jeans', 'sweat', 'heat', 'stage', 'band', 'guitarist', 'eyes']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QAgJsmIkGbf","executionInfo":{"status":"ok","timestamp":1626619862438,"user_tz":-540,"elapsed":39,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"399976e5-396a-4d7f-8292-37a10ee7a6c6"},"source":["for i in top3_df.colors:\n","  print(i)"],"execution_count":128,"outputs":[{"output_type":"stream","text":["{'gum': None, 'chewing': ('guitarist', '#a3aefe'), 'lips': ('guitarist', '#a3aefe'), 'airhead': ('guitarist', '#a3aefe'), 'hands': ('guitarist', '#a3aefe'), 'sexiest': None, 'seductive': ('sexy', '#fea3d9'), 'perfume': None, 'stunning': None, 'nice': None, 'outfit': ('jeans', '#a3a6fe'), 'pair': None, 'waves': ('guitarist', '#a3aefe'), 'thong': ('guitarist', '#a3aefe'), 'woman': None, 'jeans': ('jeans', '#a3a6fe')}\n","{'cold': None, 'hair': ('shirt', '#a3fedc'), 'skin': None, 'night': ('jeans', '#a3a6fe'), 'air': None, 'man': None, 'musky': None, 'scent': None, 'strip': None, 'crisp': None, 'evening': ('jeans', '#a3a6fe'), 'nice': None, 'makeup': None, 'friends': None, 'dresser': ('eyes', '#c9a3fe'), 'bed': None, 'hours': None, 'cleansing': ('guitarist', '#a3aefe'), 'midnight': None, 'middle': None, 'room': None, 'fancy': None, 'shampoo': None, 'expensive': None, 'leather': None, 'women': ('eyes', '#c9a3fe'), 'counter': None, 'bare': None, 'thin': None, 'winter': None, 'city': None, 'boots': ('guitarist', '#a3aefe'), 'trees': ('guitarist', '#a3aefe'), 'jacket': None, 'heat': ('heat', '#feb9a3'), 'warm': None, 'woman': None, 'dress': ('jeans', '#a3a6fe'), 'time': None, 'modern': None, 'projection': None}\n","{'sexy': ('sexy', '#fea3d9'), 'boots': ('guitarist', '#a3aefe'), 'bike': ('jeans', '#a3a6fe'), 'leather': None, 'day': None, 'girlfriend': None, 'shirt': ('shirt', '#a3fedc'), 'male': None, 'beholder': ('eyes', '#c9a3fe'), 'occasional': None, 'wiff': ('eyes', '#c9a3fe'), 'attention': None, 'growth': ('guitarist', '#a3aefe'), 'naked': None, 'beast': None, 'ultra': ('guitarist', '#a3aefe'), 'tobacco': None, 'feminine': None, 'unique': None, 'mysterious': ('sexy', '#fea3d9'), 'body': None, 'worn': ('jeans', '#a3a6fe')}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"4ZrnBQgLvrF1","executionInfo":{"status":"ok","timestamp":1626619652974,"user_tz":-540,"elapsed":357,"user":{"displayName":"ì§„í˜„ì˜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AFR6u4nLNgqhFQTrkgir9EiJIF7Dp-_Qg9FZ0g=s64","userId":"17511610036703028721"}},"outputId":"92f00d36-7ccc-40a6-e496-043f3de95677"},"source":["top3_df"],"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>similarity</th>\n","      <th>review</th>\n","      <th>keywords</th>\n","      <th>colors</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Shalimar Eau de Parfum Guerlain for women</td>\n","      <td>[0.9194832199600513]</td>\n","      <td>Shalimar is hands down the sexiest, most seduc...</td>\n","      <td>[gum, chewing, lips, airhead, hands, sexiest, ...</td>\n","      <td>{'gum': None, 'chewing': ('guitarist', '#fea3a...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Narciso Rodriguez For Her Narciso Rodriguez fo...</td>\n","      <td>[0.9184415210691973]</td>\n","      <td>This is certainly modern, and makes me smile. ...</td>\n","      <td>[cold, hair, skin, night, air, man, musky, sce...</td>\n","      <td>{'cold': None, 'hair': None, 'skin': None, 'ni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fahrenheit Christian Dior for men</td>\n","      <td>[0.9164512658515446]</td>\n","      <td>This beast can be ultra male, leather, boots, ...</td>\n","      <td>[sexy, boots, bike, leather, day, girlfriend, ...</td>\n","      <td>{'sexy': ('sexy', '#b7a3fe'), 'boots': ('guita...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                name  ...                                             colors\n","0          Shalimar Eau de Parfum Guerlain for women  ...  {'gum': None, 'chewing': ('guitarist', '#fea3a...\n","1  Narciso Rodriguez For Her Narciso Rodriguez fo...  ...  {'cold': None, 'hair': None, 'skin': None, 'ni...\n","2                  Fahrenheit Christian Dior for men  ...  {'sexy': ('sexy', '#b7a3fe'), 'boots': ('guita...\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":119}]}]}